{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a395d7-1f15-493b-9761-7ca888f0d82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grpcio in /opt/conda/lib/python3.11/site-packages (1.78.0)\n",
      "Requirement already satisfied: grpcio-status in /opt/conda/lib/python3.11/site-packages (1.78.0)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in /opt/conda/lib/python3.11/site-packages (from grpcio) (4.15.0)\n",
      "Requirement already satisfied: protobuf<7.0.0,>=6.31.1 in /opt/conda/lib/python3.11/site-packages (from grpcio-status) (6.33.5)\n",
      "Requirement already satisfied: googleapis-common-protos>=1.5.5 in /opt/conda/lib/python3.11/site-packages (from grpcio-status) (1.72.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install GRPC to connect to remote Spark Session\n",
    "%pip install grpcio grpcio-status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faa984eb-116f-4bd0-a2e2-2948dc19addc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gRPC version: 1.78.0\n"
     ]
    }
   ],
   "source": [
    "# Check if GRPC is installed\n",
    "import grpc\n",
    "from grpc_status import rpc_status\n",
    "print(f\"gRPC version: {grpc.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efab9c6-025b-4621-8404-30af688d8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check connection to remote Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "import sys\n",
    "\n",
    "IP = \n",
    "\n",
    "# 1. Initialize the Spark Connect Session\n",
    "try:\n",
    "    spark = SparkSession.builder \\\n",
    "        .remote(f\"sc://{IP}:15002\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    print(\"‚úÖ Successfully connected to Remote Spark!\")\n",
    "    \n",
    "    # 2. Run a small test job\n",
    "    print(\"Running test calculation...\")\n",
    "    df = spark.range(10).toDF(\"number\")\n",
    "    avg = df.agg({\"number\": \"avg\"}).collect()[0][0]\n",
    "    \n",
    "    print(f\"üìä Test Result: The average of 0-9 is {avg}\")\n",
    "    print(f\"Spark Version: {spark.version}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Connection Failed!\")\n",
    "    print(f\"Error details: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6091d54e-2f10-4089-8659-b3bfc9f2ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#PostgreSQL Port Connection Test\n",
    "#\n",
    "#If the below script fails, it is most likely because the containers were\n",
    "# started manually separately.\n",
    "#\n",
    "#Execute the following commands in the terminal to get them in the same network:\n",
    "#docker network create my-data-network\n",
    "#docker network connect my-data-network pyspark-notebook\n",
    "#docker network connect my-data-network Postgres\n",
    "#\n",
    "#After those commands, the two containers will be in the same network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6d9b4-d9b7-4b19-92f9-7a46ac242d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "# Replace with your actual Postgres container name (from `docker ps`)\n",
    "# Example: 'db', 'postgres', 'my-postgres-container'\n",
    "db_host = \"Postgres\" \n",
    "port = 5432\n",
    "\n",
    "try:\n",
    "    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    s.settimeout(2) # 2 second timeout\n",
    "    s.connect((db_host, port))\n",
    "    print(f\"‚úÖ Success! Jupyter can reach {db_host} on port {port}.\")\n",
    "    s.close()\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to connect: {e}\")\n",
    "    print(\"Tip: Ensure both containers are on the same Docker network.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b50b6581-5430-47f1-ba3d-d12ca7c70d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.11/site-packages (2.0.22)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.11-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy) (4.15.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from sqlalchemy) (3.0.0)\n",
      "Downloading psycopg2_binary-2.9.11-cp311-cp311-manylinux2014_aarch64.manylinux_2_17_aarch64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sqlalchemy psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15ff271-1bb5-4303-828e-baa458866ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#Connection test to laAPI database and create sample table.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "319b5b24-952a-4c5d-9b7d-55720903462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Table 'sample_table' created successfully in 'laAPI' as user 'myuser'.\n",
      "   (Verification passed: Table was found in the schema.)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# 1. Configuration\n",
    "db_user = \"myuser\"\n",
    "db_pass = \"abc\"\n",
    "db_host = \"Postgres\" # Replace with your actual container name\n",
    "db_port = \"5432\"\n",
    "db_name = \"laAPI\"  # The specific database\n",
    "\n",
    "# 2. Create the Connection Engine\n",
    "# Format: postgresql://user:password@host:port/database\n",
    "connection_str = f\"postgresql://{db_user}:{db_pass}@{db_host}:{db_port}/{db_name}\"\n",
    "engine = create_engine(connection_str)\n",
    "\n",
    "# 3. Create the Table\n",
    "create_table_sql = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sample_table (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name VARCHAR(50),\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# 4. Execute\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        connection.execute(text(create_table_sql))\n",
    "        connection.commit() # Important: Commit the change!\n",
    "        print(f\"‚úÖ Table 'sample_table' created successfully in '{db_name}' as user '{db_user}'.\")\n",
    "        \n",
    "        # Verify it exists\n",
    "        result = connection.execute(text(\"SELECT table_name FROM information_schema.tables WHERE table_name = 'sample_table';\"))\n",
    "        if result.fetchone():\n",
    "            print(\"   (Verification passed: Table was found in the schema.)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to create table: {e}\")\n",
    "    print(\"Tip: Ensure 'myUser' has CREATE privileges on the public schema.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de81dfc-dd5f-43ca-87e7-cea01a291068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f7890-c664-409a-b2a0-ce21126de9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
